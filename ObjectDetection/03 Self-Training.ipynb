{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892275f7",
   "metadata": {},
   "source": [
    "This script describes an iterative approach with self-training to successively extend the existing image dataset with labels as well as to train better YOLOv5 models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d910cd",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddac27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import statistics\n",
    "from psutil import virtual_memory\n",
    "import shutil\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image,ImageFile, ImageDraw,ImageFont\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e60174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check RAM\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a6b18e",
   "metadata": {},
   "source": [
    "# RAID\n",
    "In this project, it was possible to use a RAID system. Therefore, in the following the used folder structure is described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff155307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to raid\n",
    "%cd /raid/USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eee246",
   "metadata": {},
   "source": [
    "## Load YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77057a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model settings & Model meta infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \n",
    "# Model settings\n",
    "path_to_model = 'OWN_PATH/yolov5_yaml/model_settings/model_settings' # Manuelly creatd model definition.\n",
    "target_model = 'yolov5l_snake.yaml' # select your model \n",
    "shutil.copy('{}/{}'.format(path_to_model,target_model),'/raid/USER/yolov5/models') # Paste to YOLOv5 installation\n",
    "\n",
    "# Model meta infos\n",
    "path_to_meta = 'OWN_PATH/yolov5_yaml/snake_detection.yaml' # Manually created YAML\n",
    "\n",
    "shutil.copy(path_to_meta,'/raid/USER/yolov5/data') # Past to YOLOv5 installation\n",
    "\n",
    "%cd /raid/USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6dcbf",
   "metadata": {},
   "source": [
    "## Prepare data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./images'):\n",
    "    os.mkdir('./images')\n",
    "    \n",
    "if not os.path.exists('./images/all'):\n",
    "    os.mkdir('./images/all')\n",
    "    \n",
    "if not os.path.exists('./images/raw_labels'):\n",
    "    os.mkdir('./images/raw_labels')\n",
    "    \n",
    "if not os.path.exists('./images/train'):\n",
    "    os.mkdir('./images/train')\n",
    "    os.mkdir('./images/train/images')\n",
    "    os.mkdir('./images/train/labels')\n",
    "    \n",
    "if not os.path.exists('./images/val'):\n",
    "    os.mkdir('./images/val')\n",
    "    os.mkdir('./images/val/images')\n",
    "    os.mkdir('./images/val/labels')\n",
    "    \n",
    "if not os.path.exists('./runs'):\n",
    "    os.mkdir('./runs')\n",
    "    \n",
    "if not os.path.exists('./saved_models'):\n",
    "    os.mkdir('./saved_models')\n",
    "\n",
    "# Transfer of meta files    \n",
    "    \n",
    "%cd \n",
    "shutil.copy('OWN_PATH/annotation/labels/labels/classes.txt','/raid/USER/images/train/labels/classes.txt')\n",
    "shutil.copy('OWN_PATH/annotation/labels/labels/classes.txt','/raid/USER/images/val/labels/classes.txt')\n",
    "\n",
    "shutil.copy('OWN_PATH/images/all/SnakeCLEF2022-ISOxSpeciesMapping.csv','/raid/USER/images/all/SnakeCLEF2022-ISOxSpeciesMapping.csv')\n",
    "shutil.copy('OWN_PATH/images/all/SnakeCLEF2022-TestMetadata.csv','/raid/USER/images/all/SnakeCLEF2022-TestMetadata.csv')\n",
    "shutil.copy('OWN_PATH/images/all/SnakeCLEF2022-SampleSubmission.csv','/raid/USER/images/all/SnakeCLEF2022-SampleSubmission.csv')\n",
    "shutil.copy('OWN_PATH/images/all/SnakeCLEF2022-TrainMetadata.csv','/raid/USER/images/all/SnakeCLEF2022-TrainMetadata.csv')\n",
    "%cd /raid/USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd\n",
    "# TRAIN IMAGE DATA\n",
    "TRAIN_DATA_DIR = './images/all/SnakeCLEF2022-large_size.tar.gz'\n",
    "shutil.copy(TRAIN_DATA_DIR,'/raid/USER/images/all/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAL IMAGE DATA\n",
    "TEST_DATA_DIR = './images/all/SnakeCLEF2022-test_images'\n",
    "shutil.copytree(TEST_DATA_DIR,'/raid/USER/images/all/SnakeCLEF2022-test_images')\n",
    "%cd /raid/USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = tarfile.open('./images/all/SnakeCLEF2022-large_size.tar.gz')\n",
    "  \n",
    "# extracting file\n",
    "file.extractall('./images/all/')\n",
    "  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323df8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete tar.gz file\n",
    "!rm images/all/SnakeCLEF2022-large_size.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ee03e",
   "metadata": {},
   "source": [
    "## Prepare sorting the data\n",
    "Here we lay the foundation for the later sorting of the bounding boxes newly found by our YOLOv5 model. This is an important step in order to maintain the SnakeCLEF 2022 snake class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_meta = './images/all'\n",
    "df_meta_train = pd.read_csv('{}/{}'.format(path_to_meta,'SnakeCLEF2022-TrainMetadata.csv'))\n",
    "df_meta_test = pd.read_csv('{}/{}'.format(path_to_meta,'SnakeCLEF2022-TestMetadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update file_path\n",
    "df_meta_train['file_path'] = './images/all/SnakeCLEF2022-large_size/' +df_meta_train['file_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with the names of each image\n",
    "df_meta_train['name'] = ''*len(df_meta_train)\n",
    "for index, row in tqdm(df_meta_train.iterrows()):\n",
    "    df_meta_train.name.iloc[index] = row['file_path'].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ca6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_test['file_path']  = './images/all/SnakeCLEF2022-test_images/SnakeCLEF2022-large_size/'+df_meta_test['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_test['name'] = ''*len(df_meta_test)\n",
    "for index, row in tqdm(df_meta_test.iterrows()):\n",
    "    df_meta_test.name.iloc[index] = row['file_path'].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with the necessary data, including observation_id, file_path and name\n",
    "df_all = df_meta_train[['observation_id','file_path','name']]\n",
    "df_all = df_all.append(df_meta_test[['observation_id','file_path','name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1877ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa56ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision criterion for sorting is the observation_id.\n",
    "train_observation_id = df_meta_train.observation_id.unique()\n",
    "val_observation_id = df_meta_test.observation_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4643a81",
   "metadata": {},
   "source": [
    "## Create bounding boxes on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c99ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "#from yolov5 \n",
    "import utils\n",
    "display = utils.notebook_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best weight for from script 02 (baseline model)\n",
    "shutil.copy('OWN_PATH/yolov5_yaml/saved_runs/exp_OUR_NAME_FOR_THIS_MODEL/weights/best.pt', '/raid/USER/yolov5/best.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv5 model with torch\n",
    "path_to_base_model = './yolov5/best.pt'\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=path_to_base_model,force_reload=True)\n",
    "\n",
    "# move to cuda\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take notes on alle precitions \n",
    "all_predictions = pd.DataFrame(columns=['observation_id','image_path','name','label_txt','probability'])\n",
    "# Selection criteria\n",
    "p = 0.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd # => MUSS: /raid/USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13062d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagesize\n",
    "\n",
    "# Temporary saving of the found labels\n",
    "path_to_raw_labelsTXT = './images/raw_labels'\n",
    "error = False\n",
    "counter_error = 0\n",
    "\n",
    "for index, row in tqdm(df_all.iterrows()):\n",
    "    observation_id = row['observation_id']\n",
    "    file_path = row['file_path']\n",
    "    name = row['name']\n",
    "    \n",
    "    error = False\n",
    "    try: \n",
    "        # Generate prediction for each image\n",
    "        results = model(file_path)\n",
    "    except Exception as e:\n",
    "        error = True\n",
    "        print(e)\n",
    "        counter_error +=1\n",
    "        \n",
    "    if not error:\n",
    "            # Prepare result\n",
    "            results = results.pandas().xyxy[0]\n",
    "            # Get image dim.\n",
    "            x, y = imagesize.get(file_path)\n",
    "            # Save the confidence levels for a later decision\n",
    "            avg_conf = []\n",
    "            # Open a txt file to save the found bounding box. Later this is sorted correctly based on the observation_id\n",
    "            file = open('{}/{}.txt'.format(path_to_raw_labelsTXT,file_path.split('/')[-1].split('.')[0]),'w')\n",
    "            \n",
    "            tmp = pd.DataFrame(columns=['observation_id','image_path','name','label_txt','probability'])\n",
    "            \n",
    "            for index, row in results.iterrows():\n",
    "                X0 = (row['xmax'] + row['xmin']) // 2 # BBox X Center\n",
    "                Y0 = (row['ymax'] + row['ymin']) // 2 # BBox Y Center\n",
    "                W = row['xmax'] - row['xmin'] # Width\n",
    "                H = row['ymax'] - row['ymin'] # Height\n",
    "\n",
    "                # print('0 {} {} {} {}'.format(X0/x,Y0/y,W/x,H/y))\n",
    "                # Onyl store bounding boxes that are above the specified value p.\n",
    "                if row['confidence'] >= p:\n",
    "                    avg_conf.append(row['confidence'])\n",
    "                    file.write('0 {} {} {} {}\\n'.format(X0/x,Y0/y,W/x,H/y))\n",
    "                    tmp = tmp.append({'observation_id':observation_id,'image_path':file_path,'name':name,'label_txt':file_path.split('/')[-1].split('.')[0],'probability':row['confidence']},ignore_index=True)\n",
    "            \n",
    "            file.close()\n",
    "            # If at least one bounding box is present, then:\n",
    "            if len(avg_conf) > 0:\n",
    "                # save the found bounding boxes for the following sorting process\n",
    "                if statistics.mean(avg_conf) >= p:\n",
    "                    all_predictions = all_predictions.append(tmp)\n",
    "\n",
    "\n",
    "print('Errors: ', counter_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df\n",
    "all_predictions.to_csv('./images/all_predictions_run_{}.csv'.format(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277cabea",
   "metadata": {},
   "source": [
    "## Sort images and bounding boxes\n",
    "Later, a slightly different selection method of the bounding box is used. For the sake of completeness, tha old method is still listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_observation_id val_observation_id\n",
    "# Wir können an dieser Stelle, das Skript laufen lassen, obwohl Duplicate vorhanden sind. (Dieser werden über try except abgefangen)\n",
    "counter_train = 0\n",
    "counter_val = 0\n",
    "\n",
    "\n",
    "for index, row in tqdm(all_predictions.iterrows()):\n",
    "    observation_id = row['observation_id']\n",
    "    image_path = row['image_path']\n",
    "    label_txt_path = './images/raw_labels/' + str(row['label_txt']) + '.txt'\n",
    "    probability = row['probability']\n",
    "\n",
    "    if probability >= p:\n",
    "        \n",
    "        if observation_id in train_observation_id:\n",
    "            # training\n",
    "            try:\n",
    "                shutil.move(image_path, './images/train/images/')\n",
    "                shutil.move(label_txt_path, './images/train/labels/')\n",
    "                counter_train +=1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        elif observation_id in val_observation_id:\n",
    "            # val\n",
    "            try:\n",
    "                shutil.move(image_path, './images/val/images/')\n",
    "                shutil.move(label_txt_path, './images/val/labels/')\n",
    "\n",
    "                counter_val +=1\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            print('Error in observation_id ',observation_id,image_path)\n",
    "    \n",
    "print('Train counter ', counter_train)\n",
    "print('Val counter ', counter_val)\n",
    "print('Total: ',counter_train+counter_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446c46b",
   "metadata": {},
   "source": [
    "## Train new YOLOv5 model\n",
    "It is important to adjust the model meta data, i.e. where YOLOv5 findes the corresponding data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "#from yolov5 \n",
    "import utils\n",
    "display = utils.notebook_init()\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813277f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/train.py --img 640 --batch 26 --cfg yolov5/models/yolov5l_snake.yaml --epochs 100 --data yolov5/data/snake_detection.yaml --weights yolov5l.pt #--cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save run\n",
    "run = 'exp' # \n",
    "model_name = 'yolov5l_640' #\n",
    "\n",
    "shutil.copytree('./yolov5/runs/train/{}'.format(run),'./saved_runs/{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4057c82",
   "metadata": {},
   "source": [
    "## Next iteration of predicting bounding boxes\n",
    "We want to edit all images that have not yet been sorted (bad BBox value) with the new model. To do this, we first need to find out which images are already sorted. We can do this with the file ./images/all_predictions_run_0.csv. Here are all images with a BBox value >= p in it.\n",
    "\n",
    "## < Entry point for any following iteration >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how much data is available. This number mus be slightly larger in each iteration\n",
    "print('Images TRAIN: ', len(os.listdir('./images/train/images')))\n",
    "print('Labels TRAIN: ', len(os.listdir('./images/train/labels')))\n",
    "print('')\n",
    "print('Images VAL: ', len(os.listdir('./images/val/images')))\n",
    "print('Labels VAL: ', len(os.listdir('./images/val/labels')))\n",
    "print('')\n",
    "print('Total images ',len(os.listdir('./images/train/images'))+len(os.listdir('./images/val/images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d16350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find all images that already have a matching bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c4fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_names = os.listdir('./images/train/images')\n",
    "\n",
    "train_file_names_df = pd.DataFrame()\n",
    "\n",
    "for file_name in tqdm(train_file_names):\n",
    "    train_file_names_df = train_file_names_df.append([file_name.split('/')[-1].split('.')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8851e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_file_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca71f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_names = os.listdir('./images/val/images')\n",
    "\n",
    "test_file_names_df = pd.DataFrame()\n",
    "\n",
    "for file_name in tqdm(test_file_names):\n",
    "    test_file_names_df = test_file_names_df.append([file_name.split('.')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_file_names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list with all edited images names\n",
    "df_file_name_all = train_file_names_df\n",
    "df_file_name_all = df_file_name_all.append(test_file_names_df)\n",
    "name_already_processed = df_file_name_all.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_already_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecdd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for i in tqdm(name_already_processed):\n",
    "    for j in i:\n",
    "        new_list.append(j)\n",
    "name_already_processed = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_meta = './images/all'\n",
    "df_meta_train = pd.read_csv('{}/{}'.format(path_to_meta,'SnakeCLEF2022-TrainMetadata.csv'))\n",
    "df_meta_test = pd.read_csv('{}/{}'.format(path_to_meta,'SnakeCLEF2022-TestMetadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfee28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75749449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_train['name'] = ''*len(df_meta_train)\n",
    "for index, row in tqdm(df_meta_train.iterrows()):\n",
    "    df_meta_train.name.iloc[index] = row['file_path'].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all train data without the observation_id in df_already_sorted\n",
    "counter_not_in = 0\n",
    "counter_in = 0\n",
    "\n",
    "df_meta_train_2 = pd.DataFrame()\n",
    "\n",
    "for index, row in tqdm(df_meta_train.iterrows()):\n",
    "    if row['name'] not in name_already_processed:\n",
    "        df_meta_train_2 = df_meta_train_2.append(row)\n",
    "        counter_not_in += 1\n",
    "    else:\n",
    "        counter_in +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NOT in: ',counter_not_in)\n",
    "print('IN: ',counter_in)\n",
    "print('total: ',counter_not_in+counter_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05903301",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_meta_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update file_path\n",
    "df_meta_train_2['file_path'] = './images/all/SnakeCLEF2022-large_size/' +df_meta_train_2['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "df_meta_train_2.to_csv('./images/all/df_meta_train_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e69fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_train = pd.read_csv('./images/all/df_meta_train_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d75612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f87537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_test['name'] = ''*len(df_meta_test)\n",
    "for index, row in tqdm(df_meta_test.iterrows()):\n",
    "    df_meta_test.name.iloc[index] = row['file_path'].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all val or test data without the observation_id in df_already_sorted\n",
    "counter_not_in = 0\n",
    "counter_in = 0\n",
    "\n",
    "df_meta_test_2 = pd.DataFrame()\n",
    "\n",
    "for index, row in tqdm(df_meta_test.iterrows()):\n",
    "    if row['name'] not in name_already_processed:\n",
    "        df_meta_test_2 = df_meta_test_2.append(row)\n",
    "        counter_not_in += 1\n",
    "    else:\n",
    "        counter_in +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71403f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NOT in: ',counter_not_in)\n",
    "print('IN: ',counter_in)\n",
    "print('total: ',counter_not_in+counter_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update file_path\n",
    "df_meta_test_2['file_path']  = './images/all/SnakeCLEF2022-test_images/SnakeCLEF2022-large_size/'+df_meta_test_2['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ebc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_test_2.to_csv('./images/all/df_meta_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533861a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_test = pd.read_csv('./images/all/df_meta_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6abb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64394ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_observation_id = df_meta_train.observation_id.unique()\n",
    "val_observation_id = df_meta_test.observation_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_meta_train[['observation_id','file_path','name']]\n",
    "df_all = df_all.append(df_meta_test[['observation_id','file_path','name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d64fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.observation_id = df_all.observation_id.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96ab1b",
   "metadata": {},
   "source": [
    "### Load a custom YOLOv5 with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bad01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_base_model = './saved_runs/yolov5l_OUR_NAME/weights/best.pt' # SET NEW MODEL from previouse iteration\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=path_to_base_model,force_reload=True)\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# check GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = pd.DataFrame(columns=['observation_id','image_path','name','label_txt','probability'])\n",
    "# sort criteria\n",
    "p = 0.7 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352dac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagesize\n",
    "\n",
    "path_to_raw_labelsTXT = './images/raw_labels'\n",
    "error = False\n",
    "counter_error = 0\n",
    "\n",
    "for index, row in tqdm(df_all.iterrows()):\n",
    "    observation_id = row['observation_id']\n",
    "    file_path = row['file_path']\n",
    "    name = row['name']\n",
    "    \n",
    "    error = False\n",
    "    try: \n",
    "        results = model(file_path)\n",
    "    except Exception as e:\n",
    "        error = True\n",
    "        print(e)\n",
    "        counter_error +=1\n",
    "        \n",
    "    if not error:\n",
    "            results = results.pandas().xyxy[0]\n",
    "\n",
    "            x, y = imagesize.get(file_path)\n",
    "            \n",
    "            # print('{}/{}.txt'.format(path_to_raw_labelsTXT,file_path.split('/')[-1].split('.')[0]))\n",
    "            \n",
    "            file = open('{}/{}.txt'.format(path_to_raw_labelsTXT,file_path.split('/')[-1].split('.')[0]),'w')\n",
    "            \n",
    "            for index, row in results.iterrows():\n",
    "                X0 = (row['xmax'] + row['xmin']) // 2 # BBox X Center\n",
    "                Y0 = (row['ymax'] + row['ymin']) // 2 # BBox Y Center\n",
    "                W = row['xmax'] - row['xmin'] # Width\n",
    "                H = row['ymax'] - row['ymin'] # Height\n",
    "\n",
    "                # print('0 {} {} {} {}'.format(X0/x,Y0/y,W/x,H/y))\n",
    "                # Change selection method. Unlike the previous approch, this\n",
    "                # one stores only the bounding box with the highest confidence.\n",
    "                # This works because it seems that each image in the given dataset\n",
    "                # represents exactly 1 snake.\n",
    "                \n",
    "                if row['confidence'] >= p:\n",
    "                    if row['confidence'] >= max(results['confidence']):    \n",
    "                        file.write('0 {} {} {} {}\\n'.format(X0/x,Y0/y,W/x,H/y))\n",
    "                        \n",
    "            file.close()\n",
    "            \n",
    "            if len(results) > 0:\n",
    "                all_predictions = all_predictions.append({'observation_id':observation_id,'image_path':file_path,'name':name,'label_txt':file_path.split('/')[-1].split('.')[0],'probability':row['confidence']},ignore_index=True)\n",
    "            \n",
    "            \n",
    "print('Errors: ', counter_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bf3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Errors: ', counter_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ffc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = all_predictions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c293133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "all_predictions.to_csv('./images/all_predictions_run_{}.csv'.format(4)) # change number is you have more runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = pd.read_csv('./images/all_predictions_run_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567865e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = all_predictions[['image_path','label_txt','name','observation_id','probability']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd61d32",
   "metadata": {},
   "source": [
    "### Sort again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_observation_id val_observation_id\n",
    "counter_train = 0\n",
    "counter_val = 0\n",
    "\n",
    "\n",
    "for index, row in tqdm(all_predictions.iterrows()):\n",
    "    observation_id = row['observation_id']\n",
    "    image_path = row['image_path']\n",
    "    label_txt_path = './images/raw_labels/' + str(row['label_txt']) + '.txt'\n",
    "    probability = row['probability']\n",
    "        \n",
    "    if observation_id in train_observation_id:\n",
    "        # training\n",
    "        try:\n",
    "            shutil.move(image_path, './images/train/images/')\n",
    "            shutil.move(label_txt_path, './images/train/labels/')\n",
    "            counter_train +=1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    elif observation_id in val_observation_id:\n",
    "        # val\n",
    "        try:\n",
    "            shutil.move(image_path, './images/val/images/')\n",
    "            shutil.move(label_txt_path, './images/val/labels/')\n",
    "\n",
    "            counter_val +=1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print('Error in observation_id ',observation_id,image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('New train images ', counter_train)\n",
    "print('New val images ', counter_val)\n",
    "print('Total: ',counter_train+counter_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c56adb",
   "metadata": {},
   "source": [
    "### Train a new YOLOv5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5\n",
    "#from yolov5 \n",
    "import utils\n",
    "display = utils.notebook_init()\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/train.py --img 640 --batch 16 --cfg yolov5/models/yolov5l_snake.yaml --epochs 100 --data yolov5/data/snake_detection.yaml --weights yolov5l.pt #--cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "run = 'exp'\n",
    "model_name = 'yolov5l_Iteration_X'\n",
    "shutil.copytree('./yolov5/runs/train/{}'.format(run),'./saved_runs/{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ee499",
   "metadata": {},
   "source": [
    "At this point you can jump to the entry point and perform a new iteration. Alternatively, 'train a new YOLOv5 model' can be used to train any other model with the existing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
