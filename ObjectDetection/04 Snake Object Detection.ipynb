{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9496a7c9",
   "metadata": {},
   "source": [
    "Use a YOLOv5 model to detect snakes in images and crop the image based on the bounding box. Than replace image with the new images. In the process save the width and height of the image and also xmin, ymin, xmax and ymax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0172cf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758336c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tarfile\n",
    "from PIL import Image,ImageFile, ImageDraw,ImageFont\n",
    "#https://stackoverflow.com/questions/60584155/oserror-image-file-is-truncated\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import torchvision.transforms as transforms \n",
    "from psutil import virtual_memory\n",
    "import shutil\n",
    "import os\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "#from IPython.display import Image\n",
    "\n",
    "from timm.models import create_model\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a23b4f",
   "metadata": {},
   "source": [
    "# Raid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /raid/USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed32b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old files once completely, so that the image files are clean reloaded.\n",
    "!rm -r images/all/SnakeCLEF2022-test_images\n",
    "!rm -r images/all/SnakeCLEF2022-large_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d575347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data\n",
    "TRAIN_DATA_DIR = 'OUR_PATH/images/all/SnakeCLEF2022-large_size.tar.gz'\n",
    "shutil.copy(TRAIN_DATA_DIR,'/raid/USER/images/all/') \n",
    "\n",
    "TEST_DATA_DIR = 'OUR_PATH/images/all/SnakeCLEF2022-test_images'\n",
    "shutil.copytree(TEST_DATA_DIR,'/raid/USER/images/all/SnakeCLEF2022-test_images') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece400ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNPACK\n",
    "file = tarfile.open('./images/all/SnakeCLEF2022-large_size.tar.gz')\n",
    "  \n",
    "# extracting file\n",
    "file.extractall('./images/all/')\n",
    "  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7794b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm images/all/SnakeCLEF2022-large_size.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e804fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = './saved_runs/OUR_MODEL/weights/best.pt'\n",
    "path_to_train_images = './images/all/SnakeCLEF2022-large_size/'\n",
    "path_to_test_images = './images/all/SnakeCLEF2022-test_images/SnakeCLEF2022-large_size/'\n",
    "path_to_meta_train = './images/all/SnakeCLEF2022-TrainMetadata.csv'\n",
    "path_to_meta_test = './images/all/SnakeCLEF2022-TestMetadata.csv'\n",
    "path_to_new_meta = './images/all/'\n",
    "path_to_archive = './images/all/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfab449",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "Take a picture, open it, find the snake, cut the picture based on the bounding box you found. Return the image, the snake images, the confidence and the bounding boxeen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e57e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OD_Pipeline:\n",
    "    \n",
    "    def __init__(self, model_path,force_reload=True, image_size = 380):\n",
    "        self.model_path = model_path\n",
    "        self.image_size = image_size\n",
    "        try:\n",
    "            self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path,force_reload=force_reload)\n",
    "            device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.model.to(device)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    def pipeline(self, image_path, resize):\n",
    "\n",
    "        results = self.model(image_path)\n",
    "        results = results.pandas().xyxy[0]\n",
    "        # print(results)\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        snake_images = []\n",
    "        confidence = []\n",
    "        bboxs = []\n",
    "        for index, bbox in results.iterrows():\n",
    "            confidence.append(bbox[4])\n",
    "            s_img = img.crop((int(bbox[0]),int(bbox[1]),int(bbox[2]),int(bbox[3])))\n",
    "            if resize:\n",
    "                s_img = s_img.resize((self.image_size,self.image_size))\n",
    "            snake_images.append(s_img)\n",
    "            bboxs.append([(int(bbox[0]),int(bbox[1]),int(bbox[2]),int(bbox[3]))])\n",
    "\n",
    "        return (img, snake_images, confidence, bboxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7519829",
   "metadata": {},
   "source": [
    "## Use OD Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a694266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train meta\n",
    "df_train = pd.read_csv(path_to_meta_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change file_path\n",
    "df_train.file_path = path_to_train_images + df_train.file_path\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test meta\n",
    "df_test = pd.read_csv(path_to_meta_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.file_path = path_to_test_images + df_test.file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline object\n",
    "snake_detecting_pipeline = OD_Pipeline(path_to_model,force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_snakes = pd.DataFrame()\n",
    "df_error_images = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87751574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all important information\n",
    "df_train_prepaired = pd.DataFrame(columns=['observation_id', 'endemic', 'binomial_name', 'country', 'code',\n",
    "       'class_id', 'file_path','img_width','img_height','xmin','ymin','xmax','ymax','confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an error with one image there the ending is missing. We added manually.\n",
    "!mv ./images/all/SnakeCLEF2022-large_size/2014/Hypsiglena_ochrorhynchus/813384. ./images/all/SnakeCLEF2022-large_size/2014/Hypsiglena_ochrorhynchus/813384.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd0574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for index, row in tqdm(df_train.iterrows()):\n",
    "    #print(row)\n",
    "    image_path = row['file_path']\n",
    "\n",
    "    error = False\n",
    "    \n",
    "    try:\n",
    "        # Resize was omitted to provide more flexibility for later image manipulation.\n",
    "        img, snake_images, arr_confidence, bboxs = snake_detecting_pipeline.pipeline(image_path,resize=False)\n",
    "    except Exception as e:\n",
    "        df_error_images = df_error_images.append([image_path])\n",
    "        error = True\n",
    "        #print('#',e)\n",
    "        \n",
    "    if not error:\n",
    "        # Find max conf and save only this bbox\n",
    "        max_value_pos = -1\n",
    "        if len(arr_confidence) > 0:\n",
    "            max_value_in_arr = max(arr_confidence)\n",
    "\n",
    "            for i in range(0,len(arr_confidence)):\n",
    "                if arr_confidence[i] == max_value_in_arr:\n",
    "                    max_value_pos = i\n",
    "                    \n",
    "                    # save image -> replace old one\n",
    "                    \n",
    "                    try:\n",
    "                        snake_images[i].save(image_path)\n",
    "                    except Exception as e:\n",
    "                        print(e, image_path)\n",
    "                        df_error_images = df_error_images.append([image_path])\n",
    "                        error = True\n",
    "                    if not error:\n",
    "                        img_width, img_height = img.size\n",
    "                        # save all to new meta\n",
    "                        df_train_prepaired = df_train_prepaired.append({'observation_id':row['observation_id'],\n",
    "                                                                        'endemic':row['endemic'],\n",
    "                                                                        'binomial_name':row['binomial_name'],\n",
    "                                                                        'country':row['country'],\n",
    "                                                                        'code':row['code'],\n",
    "                                                                        'class_id':row['class_id'], \n",
    "                                                                        'file_path':row['file_path'],\n",
    "                                                                        'img_width':img_width,\n",
    "                                                                        'img_height':img_height,\n",
    "                                                                        'xmin':bboxs[i][0][0],\n",
    "                                                                        'ymin':bboxs[i][0][1],\n",
    "                                                                        'xmax':bboxs[i][0][2],\n",
    "                                                                        'ymax':bboxs[i][0][3],\n",
    "                                                                        'confidence':arr_confidence[i]},ignore_index=True)\n",
    "                    else:\n",
    "                        #error\n",
    "                        df_error_images = df_error_images.append([image_path])\n",
    "                    # break the loop\n",
    "                    break\n",
    "        else:\n",
    "            df_no_snakes = df_no_snakes.append([image_path])\n",
    "\n",
    "print('Duration: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29473dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prepaired.to_csv(path_to_new_meta+'SnakeCLEF2022_TrainMetadata_preprocessed_with_snake_detection_no_resize_OUR_NAME.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59be21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20389f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df_test\n",
    "df_test_prepaired = pd.DataFrame(columns=['observation_id','endemic','country','code','file_path','img_width','img_height','xmin','ymin','xmax','ymax','confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(df_test.iterrows()):\n",
    "    #print(row)\n",
    "    image_path = row['file_path']\n",
    "\n",
    "    error = False\n",
    "    \n",
    "    try:\n",
    "        img, snake_images, arr_confidence, bboxs = snake_detecting_pipeline.pipeline(image_path,resize=False)\n",
    "    except Exception as e:\n",
    "        df_error_images = df_error_images.append([image_path])\n",
    "        error = True\n",
    "        print('#',e)\n",
    "        \n",
    "    if not error:\n",
    "        # Find max conf and save only this bbox\n",
    "        max_value_pos = -1\n",
    "        if len(arr_confidence) > 0:\n",
    "            max_value_in_arr = max(arr_confidence)\n",
    "\n",
    "            for i in range(0,len(arr_confidence)):\n",
    "                if arr_confidence[i] == max_value_in_arr:\n",
    "                    max_value_pos = i\n",
    "                    # save image -> replace old one\n",
    "                    # print('scr/dst',image_path)\n",
    "                    snake_images[i].save(image_path)\n",
    "                    img_width, img_height = img.size\n",
    "                    # save all to new meta\n",
    "                    df_test_prepaired = df_test_prepaired.append({'observation_id':row['observation_id'],\n",
    "                                                                    'endemic':row['endemic'],\n",
    "                                                                    'country':row['country'],\n",
    "                                                                    'code':row['code'],\n",
    "                                                                    'file_path':row['file_path'],\n",
    "                                                                    'img_width':img_width,\n",
    "                                                                    'img_height':img_height,\n",
    "                                                                    'xmin':bboxs[i][0][0],\n",
    "                                                                    'ymin':bboxs[i][0][1],\n",
    "                                                                    'xmax':bboxs[i][0][2],\n",
    "                                                                    'ymax':bboxs[i][0][3],\n",
    "                                                                    'confidence':arr_confidence[i]},ignore_index=True)\n",
    "                    # break the loop\n",
    "                    break\n",
    "        else:\n",
    "            df_no_snakes = df_no_snakes.append([image_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e389dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prepaired.to_csv(path_to_new_meta+'SnakeCLEF2022_TestMetadata_preprocessed_with_snake_detection_no_resize_OUR_NAME.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911fef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'No snakes' is not a reliable table, just an indication in which images no snake was detected.\n",
    "df_no_snakes.to_csv(path_to_new_meta+'No_snakes_found_in_image_OUR_NAME.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecae45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the images where there ma have been problemens\n",
    "df_error_images.to_csv(path_to_new_meta+'Error_images_in_preprocessing_snake_OD_OUR_NAME.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26ec07",
   "metadata": {},
   "source": [
    "At this point, all images were loaded once from the selected YOLOv5 model, if possible a snake was detected and replaced as a cropped partial image in the same location. Now a classification model can be trained and used for predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
