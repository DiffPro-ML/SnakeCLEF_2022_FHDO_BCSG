{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.optim import SGD\n",
    "from torch import tensor\n",
    "from torch import max as torchmax\n",
    "from torch import save as torchsave\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.cuda import is_available\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from timm.models import create_model\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "\n",
    "from livelossplot import PlotLosses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and labels\n",
    "TRAIN_DATA_DIR = \"/dir/to/traindata/\"\n",
    "TEST_DATA_DIR = \"/dir/to/testdata/\"\n",
    "TRAIN_LABELS_DIR=os.path.abspath(\"/dir/to/trainmetadata/SnakeCLEF2022-TrainMetadata.csv\")\n",
    "TEST_LABELS_DIR=os.path.abspath(\"/dir/to/testmetadata/SnakeCLEF2022-TestMetadata.csv\")\n",
    "# Select a folder, where to save models\n",
    "MODEL_DIR = os.path.join(\"/dir/to/save/models/\")\n",
    "\n",
    "# set additional parameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS=30\n",
    "IMAGE_SIZE = 384 \n",
    "trainingDataset=pd.read_csv(TRAIN_LABELS_DIR)\n",
    "learning_rate=0.1\n",
    "threshold_early_stopping=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataset[\"image_path\"]=TRAIN_DATA_DIR+trainingDataset.file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAINING_SAMPLES=trainingDataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeTrainDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data=data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_obj = self.data.iloc[index]\n",
    "        img = Image.open(img_obj.image_path).convert(\"RGB\")\n",
    "        y_label = tensor(img_obj.class_id)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\"tf_efficientnetv2_m_in21k\",\n",
    "        pretrained=True,\n",
    "        num_classes=trainingDataset.class_id.unique().shape[0],\n",
    "        drop_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((int(IMAGE_SIZE+IMAGE_SIZE*0.1), int(IMAGE_SIZE+IMAGE_SIZE*0.1))),\n",
    "            transforms.RandomCrop((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "datasetTrain = SnakeTrainDataset(trainingDataset,transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=datasetTrain, shuffle=True, batch_size=BATCH_SIZE,num_workers=4)\n",
    "\n",
    "EPOCH_LENGTH=datasetTrain.__len__()//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "liveloss = PlotLosses()\n",
    "epoch=0\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, 5,2)\n",
    "while (epoch<=NUM_EPOCHS):\n",
    "    epoch+=1\n",
    "    #initialize logs used for live plotting\n",
    "    logs = {}\n",
    "    #initialize epoch starting time\n",
    "    start = time.time()\n",
    "    preds_epoch=[]\n",
    "    label_epoch=[]\n",
    "    model.train()\n",
    "    loader=train_loader\n",
    "    running_loss = 0.0\n",
    "    #iterate over all minibatches of the dataset\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        # get the images and labels of one mini batch and convert to GPU readable format\n",
    "        inputs, labels = data\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        # mixed precision\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(epoch + i / iters)\n",
    "        _, preds = torchmax(outputs, 1)\n",
    "        preds_epoch.append(preds.cpu().detach().numpy())\n",
    "        label_epoch.append(labels.data.cpu().detach().numpy())\n",
    "        running_loss += loss.detach() * inputs.size(0)\n",
    "    #flatten predictions and labels of epoch\n",
    "    preds_epoch = [item for sublist in preds_epoch for item in sublist]\n",
    "    label_epoch = [item for sublist in label_epoch for item in sublist]\n",
    "    #calculate epoch loss for training dataset\n",
    "    epoch_loss = running_loss / NUM_TRAINING_SAMPLES\n",
    "    logs['log loss'] = epoch_loss.item()\n",
    "    logs['f1'] = f1_score(preds_epoch,label_epoch,average=\"macro\")\n",
    "\n",
    "    #update plot\n",
    "    liveloss.update(logs)\n",
    "    liveloss.send()\n",
    "    torchsave(model.state_dict(),MODEL_DIR+\"model_\"+str(epoch)+\".pth\")\n",
    "    end = time.time()\n",
    "    print('{:5.3f}s'.format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
